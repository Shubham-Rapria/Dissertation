{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71a876e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "import matplotlib as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76ebd621",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\caps_food\\lib\\site-packages\\fuzzywuzzy\\fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] VolumeEstimator not initialized.\n",
      "WARNING:tensorflow:From E:\\Anaconda3\\envs\\caps_food\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From E:\\Anaconda3\\envs\\caps_food\\lib\\site-packages\\food_volume_estimation-0.3-py3.6.egg\\food_volume_estimation\\depth_estimation\\project.py:199: calling squeeze (from tensorflow.python.ops.array_ops) with squeeze_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the `axis` argument instead\n",
      "WARNING:tensorflow:From E:\\Anaconda3\\envs\\caps_food\\lib\\site-packages\\food_volume_estimation-0.3-py3.6.egg\\food_volume_estimation\\depth_estimation\\project.py:236: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "[*] Loaded depth estimation model.\n"
     ]
    }
   ],
   "source": [
    "from volume_estimator1 import VolumeEstimator \n",
    "import sys\n",
    "import json\n",
    "from keras.models import Model, model_from_json\n",
    "from food_volume_estimation.depth_estimation.custom_modules import *\n",
    "from food_volume_estimation.food_segmentation.food_segmentator import FoodSegmentator\n",
    "import matplotlib.pyplot as plt\n",
    "from pyntcloud import PyntCloud\n",
    "\n",
    "# Paths to model archiecture/weights\n",
    "depth_model_architecture = 'monovideo_fine_tune_food_videos.json'\n",
    "depth_model_weights = 'monovideo_fine_tune_food_videos.h5'\n",
    "segmentation_model_weights = 'mask_rcnn_food_segmentation.h5'\n",
    "\n",
    "# Create estimator object and intialize\n",
    "estimator = VolumeEstimator(arg_init=False)\n",
    "with open(depth_model_architecture, 'r') as read_file:\n",
    "    custom_losses = Losses()\n",
    "    objs = {'ProjectionLayer': ProjectionLayer,\n",
    "            'ReflectionPadding2D': ReflectionPadding2D,\n",
    "            'InverseDepthNormalization': InverseDepthNormalization,\n",
    "            'AugmentationLayer': AugmentationLayer,\n",
    "            'compute_source_loss': custom_losses.compute_source_loss}\n",
    "    model_architecture_json = json.load(read_file)\n",
    "    estimator.monovideo = model_from_json(model_architecture_json, custom_objects=objs)\n",
    "estimator._VolumeEstimator__set_weights_trainable(estimator.monovideo, False)\n",
    "estimator.monovideo.load_weights(depth_model_weights)\n",
    "estimator.model_input_shape = estimator.monovideo.inputs[0].shape.as_list()[1:]\n",
    "depth_net = estimator.monovideo.get_layer('depth_net')\n",
    "estimator.depth_model = Model(inputs=depth_net.inputs, outputs=depth_net.outputs, name='depth_model')\n",
    "print('[*] Loaded depth estimation model.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "accfa1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Depth model configuration\n",
    "MIN_DEPTH = 0.01\n",
    "MAX_DEPTH = 10\n",
    "estimator.min_disp = 1 / MAX_DEPTH\n",
    "estimator.max_disp = 1 / MIN_DEPTH\n",
    "estimator.gt_depth_scale = 0.333 # Ground truth expected median depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2af637a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Loading segmentation model weights mask_rcnn_food_segmentation.h5\n"
     ]
    }
   ],
   "source": [
    "# Create segmentator object\n",
    "estimator.segmentator = FoodSegmentator(segmentation_model_weights)\n",
    "\n",
    "# Set plate adjustment relaxation parameter\n",
    "estimator.relax_param = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69471ab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From E:\\Anaconda3\\envs\\caps_food\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "model_classifier = load_model('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc1592ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from mrcnn.config import Config\n",
    "from mrcnn.model import MaskRCNN\n",
    "\n",
    "# Define configuration for the model\n",
    "class InferenceConfig(Config):\n",
    "    # Give the configuration a recognizable name\n",
    "    NAME = \"segmentation_of_food\"\n",
    "\n",
    "    # Set batch size to 1 since we're running inference on a single image\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "    # Number of classes (including background)\n",
    "    NUM_CLASSES = 2  # 1 Background + 1 Object\n",
    "\n",
    "# Create config object\n",
    "config = InferenceConfig()\n",
    "\n",
    "# Create Mask R-CNN model in inference mode\n",
    "model_seg = MaskRCNN(mode=\"inference\", config=config, model_dir=\"./logs\")\n",
    "\n",
    "# Load pre-trained weights\n",
    "model_seg.load_weights(segmentation_model_weights, by_name=True)\n",
    "clusters = ['food']\n",
    "class_names = ['bg'] + clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4412562",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(path = None,field_of_view= 70,dia = 0,plot_results=False,food = None):\n",
    "\n",
    "\n",
    "    # Estimate volumes in input image\n",
    "    input_image = path\n",
    "    plate_diameter = dia # Set as 0 to ignore plate detection and scaling(diameter is in meter)\n",
    "    if food==None:\n",
    "\n",
    "#         # Load the image using the PIL library\n",
    "#         image = Image.open(path)\n",
    "\n",
    "#         # Check if height is greater than width\n",
    "#         if image.height > image.width:\n",
    "#             # Convert the image to a NumPy array\n",
    "#             image_array = np.array(image)\n",
    "\n",
    "#             # Transpose the image array\n",
    "#             transposed_array = np.transpose(image_array, (1, 0, 2))\n",
    "\n",
    "#             # Convert the transposed array back to an image\n",
    "#             transposed_image = Image.fromarray(transposed_array)\n",
    "#             image=transposed_image\n",
    "#             # Display the transposed image\n",
    "#             #transposed_image.show()\n",
    "#         else:\n",
    "#             # Display the original image\n",
    "#             image=image\n",
    "        image = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        results = model_seg.detect([image], verbose=0)\n",
    "        r = results[0]\n",
    "        out_put = []\n",
    "        for i in range(r[\"rois\"].shape[0]):\n",
    "            masked_image = cv2.bitwise_and(image, image, mask=r[\"masks\"][:,:,i].astype(np.uint8))\n",
    "            masked_image = cv2.resize(masked_image,(224,224))\n",
    "            out_put.append(masked_image)\n",
    "        lable = []\n",
    "        for i in out_put:\n",
    "            img_array = np.expand_dims(i, axis=0)\n",
    "            img_array = preprocess_input(img_array)\n",
    "            result  = model_classifier.predict(img_array)\n",
    "            classes =  ['alloo_matar', 'apple', 'banana', 'bhindi', 'carrot', 'cucumber', 'dal makhni', 'fried rice', 'Jalebi', 'orange', 'pizza', 'roti', 'samosa']\n",
    "            res = np.argmax(result)\n",
    "            lable.append(classes[res])\n",
    "\n",
    "        outputs_list = estimator.estimate_volume(input_image, fov=field_of_view, plate_diameter_prior=plate_diameter, \n",
    "                                                 plot_results=plot_results,lable=lable)\n",
    "        print(lable)\n",
    "    else: \n",
    "        outputs_list = estimator.estimate_volume(input_image, fov=field_of_view, plate_diameter_prior=plate_diameter, \n",
    "                                                 plot_results=plot_results,lable=food)\n",
    "        lable=[food]\n",
    "    \n",
    "    if plot_results:\n",
    "        out = []\n",
    "        for i in range(len(outputs_list)):\n",
    "            out.append(outputs_list[i][0])\n",
    "    else:\n",
    "        out = outputs_list\n",
    "        \n",
    "    Calories = {}\n",
    "    weights = {}\n",
    "    calaroies = pd.read_csv(\"Calories.csv\")\n",
    "    if len(lable)==len(out):\n",
    "        for i in range(len(out)):\n",
    "            vol = out[i]*1000000\n",
    "            ind = list(calaroies.loc[calaroies.name==lable[i]].index)[0]\n",
    "            wei = calaroies.density[ind] * vol\n",
    "            calory = (wei/100)*calaroies.cal[ind]\n",
    "            if wei>10:\n",
    "                if lable[i] in Calories.keys(): \n",
    "                    Calories[lable[i]] += calory\n",
    "                    weights[lable[i]] += wei\n",
    "                else:\n",
    "                    Calories[lable[i]] = calory\n",
    "                    weights[lable[i]] = wei\n",
    "    else:\n",
    "        for i in range(len(out)):\n",
    "            vol = out[i]*1000000\n",
    "            ind = list(calaroies.loc[calaroies.name==lable[0]].index)[0]\n",
    "            wei = calaroies.density[ind] * vol\n",
    "            calory = (wei/100)*calaroies.cal[ind]\n",
    "            if lable[0] in Calories.keys(): \n",
    "                Calories[lable[0]] += calory\n",
    "                weights[lable[0]] += wei\n",
    "            else:\n",
    "                Calories[lable[0]] = calory\n",
    "                weights[lable[0]] = wei\n",
    "                \n",
    "    total_cal = np.sum(list(Calories.values()))\n",
    "    total_weight = np.sum(list(weights.values()))\n",
    "    print(\"total Calories your are goint to intake is\",round(total_cal,2),\"cal\")\n",
    "    print(\"total weight of food is\",round(total_weight,2),\"gms\")\n",
    "    \n",
    "    return Calories,weights\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97021ddc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 food object(s) in image.\n",
      "total Calories your are goint to intake is 301.85 cal\n",
      "total weight of food is 736.59 gms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'carrot': 301.8546071433863}, {'carrot': 736.5900613552619})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict('carrot.jpg',plot_results=False,food=\"carrot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883ab880",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
